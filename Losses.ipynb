{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#export\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import *\n",
    "from fastai.utils.mem import *\n",
    "from fastai.vision.gan import *\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import TensorDataset\n",
    "import pdb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def mse(val, targ):\n",
    "        return 0.5 * torch.mean((val-targ)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def cov(m):\n",
    "    fact = 1.0 / (m.size(1) - 1)\n",
    "    m -= torch.mean(m, dim=1, keepdim=True)\n",
    "    mt = m.t() \n",
    "    return fact * m.matmul(mt).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def one_norm(p1, p2):\n",
    "    return (p1-p2).abs().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_adv_loss(preds):\n",
    "    loss = 0\n",
    "    for pred in preds:\n",
    "        loss += mse(pred, torch.ones(pred.shape))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_rec_loss(orig, orig2, orig_recon, orig2_recon, cycled_orig, \\\n",
    "                cycled_orig2, one_rand, two_rand, one_rand_recon, two_rand_recon):\n",
    "    return one_norm(orig, orig_recon) + one_norm(orig2, orig2_recon) + one_norm(orig, cycled_orig) \\\n",
    "                + one_norm(orig, cycled_orig2) + one_norm(one_rand, one_rand_recon) \\\n",
    "                + one_norm(two_rand, two_rand_recon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_latent_loss(l1, l2, l1rec, l2rec):\n",
    "    return one_norm(l1, l1rec) + one_norm(l2, l2rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_sdist_loss(orig_style, orig2_style, styles):\n",
    "    styles = torch.cat([orig_style, orig2_style, *styles])\n",
    "    \n",
    "    smeans = styles.mean()\n",
    "    cov_m = cov(styles)\n",
    "    cov_diag = torch.diag(cov_m)\n",
    "    \n",
    "    return one_norm(smeans, torch.ones(1)) + one_norm(cov_m, torch.eye(cov_m.shape[0])) \\\n",
    "            + one_norm(cov_diag, torch.ones(cov_diag.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "bce = nn.BCELoss()\n",
    "def get_seg_loss(orig_seg, orig2_seg, one2two_seg, two2one_seg, one_rand_seg, two_rand_seg):\n",
    "    orig, orig2 = orig_seg.detach(), orig2_seg.detach()\n",
    "    return bce(one2two_seg, orig) + bce(two2one_seg, orig2) + bce(one_rand_seg, orig) \\\n",
    "            + bce(two_rand_seg, orig2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class HiDTLoss(GANModule):\n",
    "    \"Loss function wrapper\"\n",
    "    def __init__(self, loss_funcG:Callable, loss_funcC:Callable, model):\n",
    "        super().__init__()\n",
    "        self.loss_funcG,self.loss_funcC,self.model = loss_funcG,loss_funcC,model\n",
    "        self.content_encoder, self.style_encoder, self.decoder, self.disc = model.content_encoder, model.style_encoder, model.decoder, model.discriminator\n",
    "        self.style_cap = 16\n",
    "        self.recent_styles = []\n",
    "        \n",
    "        self.lambda1, self.lambda2, self.lambda3, self.lambda4, self.lambda5, self.lambda6, self.lambda7 = 5, 2, 3, 1, 0.1, 4, 7\n",
    "        \n",
    "    def forward(self, *args):\n",
    "        if self.gen_mode:\n",
    "            return self.generator(*args)\n",
    "        else:\n",
    "            return self.discriminator(*args)\n",
    "        \n",
    "    def generator(self, output, *args):\n",
    "        orig, orig2, orig_recon, orig2_recon, orig_style, orig2_style, orig_cont, orig2_cont, \\\n",
    "        one2two, two2one, one2two_style, two2one_style, one2two_cont, two2one_cont, cycled_orig, \\\n",
    "        cycled_orig2, one_rand, two_rand, one_rand_cont, two_rand_cont, one_rand_style, \\\n",
    "        two_rand_style, one_rand_recon, two_rand_recon, rand_style, one2twoc, two2onec, one_randc, \\\n",
    "        two_randc, orig_seg, orig2_seg, one2two_seg, two2one_seg, one_rand_seg, two_rand_seg = output\n",
    "        \n",
    "        #adversarial losses\n",
    "        adv_loss = get_adv_loss([one2two, two2one, one_rand, two_rand, one2twoc, two2onec, one_randc, \\\n",
    "                    two_randc])\n",
    "        \n",
    "        #recreation losses\n",
    "        rec_loss = get_rec_loss(orig, orig2, orig_recon, orig2_recon, cycled_orig, \\\n",
    "                                cycled_orig2, one_rand, two_rand, one_rand_recon, two_rand_recon)\n",
    "        \n",
    "        #TODO: pretrain segmenter on dataset\n",
    "        seg_loss = get_seg_loss(orig_seg, orig2_seg, one2two_seg, two2one_seg, one_rand_seg, two_rand_seg)\n",
    "        \n",
    "        #latent code losses\n",
    "        lat_style_loss = get_latent_loss(orig_style, orig2_style, one2two_style, two2one_style)\n",
    "        lat_style_rand_loss =  get_latent_loss(rand_style, rand_style, one_rand_style, two_rand_style)\n",
    "        lat_cont_loss = get_latent_loss(orig_cont, orig2_cont, one2two_cont, two2one_cont)\n",
    "        lat_cont_loss += get_latent_loss(orig_cont, orig2_cont, one_rand_cont, two_rand_cont)\n",
    "        \n",
    "        #style distribution loss\n",
    "        sdist_loss = get_sdist_loss(orig_style, orig2_style, self.recent_styles)\n",
    "        \n",
    "        self.recent_styles.extend([orig_style.data, orig2_style.data])\n",
    "        \n",
    "        if len(self.recent_styles) >= self.style_cap:\n",
    "            self.recent_styles = self.recent_styles[2:]\n",
    "        \n",
    "        return self.lambda1*adv_loss + self.lambda2*rec_loss + self.lambda3*seg_loss \\\n",
    "                    + self.lambda4*lat_cont_loss \\\n",
    "                    + self.lambda5*lat_style_loss + self.lambda6*lat_style_rand_loss \\\n",
    "                    + self.lambda7 * sdist_loss\n",
    "\n",
    "    def discriminator(self, output, *args):\n",
    "        orig, orig2, one2two, two2one, one2twoc, two2onec, origc, orig2c = output\n",
    "        \n",
    "        return mse(orig, torch.ones(orig.shape)) + mse(orig2, torch.ones(orig2.shape)) \\\n",
    "                + mse(one2two, torch.zeros(one2two.shape)) + mse(orig, torch.zeros(two2one.shape)) \\\n",
    "                + mse(one2twoc, torch.zeros(one2twoc.shape)) + mse(two2onec, torch.zeros(two2onec.shape)) \\\n",
    "                + mse(origc, torch.ones(origc.shape)) + mse(orig2c, torch.ones(orig2c.shape)) \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
