{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from your_lib.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HiDT \n",
    "\n",
    "> Recration of the High-Resolution Daytime Translation without Domain Labels paper in PyTorch. This is an unnoficial implementation. For the original work please see [here](http://openaccess.thecvf.com/content_CVPR_2020/papers/Anokhin_High-Resolution_Daytime_Translation_Without_Domain_Labels_CVPR_2020_paper.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background on HiDT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous unsupervised image to image translation architectures such as UNIT, MUNIT and FuNIT have progressively gotten better at working with more general datasets. UNIT eliminated the requirement of having paired labels of data in two seperate domains by creating a latent space assumption and attempting to create models to map to and from this space from each domain. MUNIT expanded on this work by allowing images from more than 2 domain be translated. More recently, FuNIT expanded this further by allowing to train on brand new classes of a only a few examples, but still requires large amounts domain labels for training. The natural progression in these models then becomes, is there a way to train on any random groups of pictures, without any labelling which is exactly what HiDT aims to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specifics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifically, HiDT presents 3 contributions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "<li> Creating a model to train on a large amount of unlabelled and unalliigned (no inter-domain matching) images \n",
    "    <img src=\"model.png\">\n",
    "    Code for this can be found in \"Training\"\n",
    "<li> Generator for image to image translation combining AdaINs and skip connections\n",
    "    <img src=\"adaptiveunet.png\">\n",
    "    Code for this can be found in \"Adaptive Unet\"\n",
    "<li> A new enhancement method for training translation models on high resolution images\n",
    "<ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li> Implement enhancement scheme postprocessing for high res translations\n",
    "    <li> Test schedulers on discriminator/generator training split\n",
    "    <li> Test custom segmentation model using encoder features\n",
    "    <li> Benchmark half precision train time\n",
    "<ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
